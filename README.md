[Execution Steps.pdf](https://github.com/SaiTejaShashank/File-Based-Malware-Detection-using-Ensemble-Method/files/7052035/Execution.Steps.pdf)
# File-Based-Malware-Detection-using-Ensemble-Method
1. Download the asm and byte files from Kaggle using the 
link: https://www.kaggle.com/c/malware-classification/data
2. Place the jupyter notebook file and the files in the same folder
3. Install all the libraries that are missing to run the project
4. Run the jupyter notebook cells one by one to see the output.

# Data Overview
Source : https://www.kaggle.com/c/malware-classification/data
For every malware, we have two files
.asm file (read more: https://www.reviversoft.com/file-extensions/asm)
.bytes file (the raw data contains the hexadecimal representation of the file's binary content, without the PE header)
Total train dataset consist of 200GB data out of which 50Gb of data is .bytes files and 150GB of data is .asm files:
Lots of Data for a single-box/computer.
There are total 10,868 .bytes files and 10,868 asm files total 21,736 files
There are 9 types of malwares (9 classes) in our give data
Types of Malware:
Ramnit
Lollipop
Kelihos_ver3
Vundo
Simda
Tracur
Kelihos_ver1
Obfuscator.ACY
Gatak

# Performance Metrics Used

Source: https://www.kaggle.com/c/malware-classification#evaluation

Metric(s):
* Multi class log-loss
* Confusion matrix

# Machine Learing Objectives and Constraints
Objective: Predict the probability of each data-point belonging to each of the nine classes.

Constraints:
* Class probabilities are needed.
* Penalize the errors in class probabilites => Metric is Log-loss.
* Some Latency constraints.

# Conclusion

XgBoost outperformed Random Forest, Logistic Regression and K NN and achieved a multiclass log loss of 0.031




